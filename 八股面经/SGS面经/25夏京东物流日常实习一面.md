# 25 夏京东物流日常实习一面 50min

## 面试官介绍

京东物流 工业链行业开发

## 自我介绍

## 项目拷打 25min

项目亮点、难点 x 2

## 八股拷打 25min

- Java 中集合的了解

  - HashTable 和 ConcurrentHashMap 的区别

  - HashMap 的扩容详情

  - SQL 语句在 InnoDB 中的执行过程

  - 数据直接写入磁盘还是经过什么步骤

  - 隔离级别有什么？可重复读如何解决前两个级别的问题？

  - 如何处理慢 SQL？

  - 索引失效的情况有哪些

  - 分别解释一下 RedoLog、UndoLog、BinLog？应用场景？

  - 为什么使用 B+ 树作为索引的数据结构？为什么不用哈希表或二叉树？

## 八股总结

### HashTable 和 ConcurrentHashMap 的区别

同样都是线程安全，但是**设计思想**、**性能**、**使用场景**、**实现机制**有明显差异

- 线程安全的实现方式

  | 项目     | Hashtable                      | ConcurrentHashMap                             |
  | -------- | ------------------------------ | --------------------------------------------- |
  | 实现方式 | **方法级加锁**（synchronized） | **更细粒度的锁（段锁 / CAS + synchronized）** |
  | 锁粒度   | 粗：整个对象                   | 细：分段锁（JDK8 前）或每个桶（JDK8 后）      |
  | 性能     | 低（多个线程会阻塞）           | 高（并发读写效率更好）                        |

- 性能差异：

  - `HashTable`：**全表加锁**，多个线程只能一个一个访问，效率低

  - `ConcurrentHashMap`：**分段或节点加锁**，允许多个线程并发读写不同段或桶，**吞吐量更高**

- 底层结构：

  | 项目              | JDK7                 | JDK8                       |
  | ----------------- | -------------------- | -------------------------- |
  | Hashtable         | 数组 + 链表          | 数组 + 链表                |
  | ConcurrentHashMap | 分段锁 + 数组 + 链表 | 数组 + 链表 + 红黑树 + CAS |

- 对于 null 的支持

  | 项目              | 是否允许 key/value 为 null         |
  | ----------------- | ---------------------------------- |
  | Hashtable         | ❌ 不允许 key 或 value 为 null     |
  | ConcurrentHashMap | ❌ 同样不允许 key 或 value 为 null |

- 读写并发能力：

  | 操作     | Hashtable      | ConcurrentHashMap                          |
  | -------- | -------------- | ------------------------------------------ |
  | 多线程读 | 会阻塞（加锁） | 高并发读不加锁（用 `volatile` 保证可见性） |
  | 多线程写 | 阻塞严重       | 写操作只锁桶或用 `CAS`，无需全表阻塞       |

### HashMap 的扩容详情

- 扩容条件：

  - **当前元素个数 >= 阈值（capacity x loadFactor）**

  - **put 的 key 发生哈希冲突，导致链表或树高度过高**

- 扩容过程：

  - **新建一个是原数组 2 倍长度的新数组**

  - **将原数组所有元素重新计算 hash 值并移动到新位置 rehash**

  - 原链表的元素可能：**保持在原位置**；**移动到 index + oldCapacity 的新位置**

- 扩容为原数组的 2 倍的原因：

  - 扩容后，`index = hash & (nweLength - 1)` 更容易定位新位置，只涉及 **第一个额外的高位 bit 的变化**，计算更高效

  - 假设旧 index 是 `i`，那么扩容后的位置可能是： `i` （高位为 0）；`i + oldCapacity`（高位为 1），**无需重新 hash**

- 扩容带来的性能影响：

  - Rehash 开销大：扩容时重新计算位置

  - 影响性能：大量数据时扩容会导致 STW 卡顿

  - 影响并发安全

- 对于大数据 HashMap 进行扩容时，所有旧数据都要重新计算`hash`放到新数组中？

  - 不是完全重新计算 hash，而是复用原 hash，通过位运算判断新位置

  - 迁移时每个桶内的链表或红黑树节点会分成两组：

    - 一组 hash 的某位为 0：仍放在圆桶

    - 一组 hash 的某位为 1：移到新桶 = 原桶 + oldCapacity

### 执行一条 SQL 的过程是怎么样的？

- 客户端连接

  - 客户端通过 TCP/IP 协议连接到 MySQL 服务器

  - 连接器负责建立连接、身份认证、权限认证

- 语法解析

  - 检查 SQL 是否符合语法规范（如 `SELECT` 后必须有字段）。

  - 将 SQL 字符串转换为 **解析树（Parse Tree）**。

  - 会进行词法分析、语法分析。

- 查询优化

  - 根据解析树生成执行计划（比如使用哪个索引、排序方式、连接顺序）

  - 会尝试生成代价最低的执行方案：

    - 是否使用索引？

    - 哪张表先查？

    - 全表扫描还是索引范围扫描？

- 权限验证（访问控制）

  - 在执行前，会检查当前用户是否对目标表有 `SELECT` 权限

  - 权限不足则中断执行，抛出 `ERROR 1044` 等错误

- 查询执行

  - 执行器按照优化器生成的执行计划执行 SQL

  - 代替部分对应的 **存储引擎接口** 来读取数据

- 存储引擎访问（InnoDB）

  - 具体的数据读写由底层存储引擎负责：

    - 索引查找 - B+树

    - 页缓存 - Buffer Pool

    - 多版本控制 - MVCC

    - 锁控制 - 行锁、间隙锁

- 返回结果

  - 将结果通过 MySQL 协议返回给客户端

  - 结果集通常会先存放在服务端的内存中（或磁盘临时文件中），在逐步发送到客户端

### 数据写入的流程是什么？

- **数据不是直接写入磁盘**，而是经过一系列中间步骤来**提高性能**、**保证事务一致性**和**容错能力**。

- 完整流程：

  - **写入缓冲池**（Buffer Pool）

    - SQL 执行时，数据先写入 **内存页**

    - 变更记录在内存中，称为 **脏页**

  - **写入 RedoLog**（物理日志）

    - 同时记录变更操作到 `RedoLog`（重做日志）

    - RedoLog 是顺序写入，非常快

    - 写入完后执行 `fsync` 落盘：**此时事务可以提交**

  - **刷写磁盘**

    - 后台线程负责将脏页异步刷盘（并非立刻）

    - 会定期触发或者内存满触发

  - **写入 UndoLog**

    - 用于事务回滚

    - 事务执行前先生成 Undo Log，支持原子性和一致性

### 事务的隔离级别有哪些？实现原理是什么？

- **读未提交**

  - 所有事务都可以读取其他事务未提交的数据；

  - 实现方式：不加锁，直接读取最新数据；

  - 风险：会发生 **脏读** ，一致性最差。

- **读已提交**

  - 每次查询只能读取其他事务已提交的数据；

  - 实现方式：快照读（使用 MVCC），只能读取已提交的数据；

  - 仍可能发生 **不可重复读** 和 **幻读**；

  - Oracle 默认使用该隔离级别。

- **可重复读**

  - 一个事务中多次读取同一数据，结果一致；

  - 实现方式：MVCC（避免脏读；避免不可重复读：事务期间读取的是事务启动时的快照） + 间隙锁（Gap Lock）；

  - InnoDB 中通过 **快照版本号** 保证重复读一致；

  - 幻读也可通过加锁机制防止（如 `select ... for update`）。

- **串行化**

  - 所有事务串行执行（加表级锁或行级锁），读操作加共享锁；

  - 最严格，**避免所有并发问题**；

  - 实现方式：

    - 行锁 + 共享锁/排它锁；

    - 或通过乐观锁/序列号控制；

  - 性能最差，不常用于高并发场景。

设置隔离级别（只对当前 session 生效）

```sql
SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
```

### 如何优化慢 SQL？

优化慢 SQL 是数据库调优的重要环节，常见的优化思路是从 **语句本身**、**索引设计**、**表结构设计**、**执行计划分析**、**数据库参数**等多个维度 出发。

1. 定位慢 SQL 的方法

   - 慢查询日志

     - 开启方式：

       ```sql
       SET GLOBAL slow_query_log = 1;
       SET GLOBAL long_query_time = 1;
       ```

   - EXPLAIN 分析执行计划

   - 一系列 DBA 工具

2. 优化 SQL 语句

   - SQL 语法层面优化

   | 问题                    | 优化建议                               |
   | ----------------------- | -------------------------------------- |
   | 使用 `SELECT *`         | 改为只查需要的字段                     |
   | OR 查询                 | 改为 `UNION` 或分段查                  |
   | 模糊查询 `%xxx`         | 改用倒排索引、全文索引、或搜索引擎     |
   | 不必要的子查询/嵌套查询 | 优化为 JOIN                            |
   | 过多函数计算            | 尽量避免函数用于索引列（无法使用索引） |

   - 索引优化

   | 问题               | 优化建议                                          |
   | ------------------ | ------------------------------------------------- |
   | 没有索引           | 建立合适的索引（单列/联合）                       |
   | 索引未命中         | 使用 `EXPLAIN` 分析为什么没有走索引               |
   | 覆盖索引未使用     | 可通过调整字段顺序使用索引                        |
   | 索引列参与函数运算 | 函数计算会失效索引，如 `YEAR(create_time) = 2024` |
   | 索引失效           | 如 `!=`、`OR`、`IS NULL`、隐式类型转换            |

   - 表结构优化

     - 选择合适的数据类型（如 VARCHAR(20) 优于 TEXT）

     - 减少大字段（如 BLOB、TEXT）的使用或拆分冷热数据表

     - 水平分表或垂直分表

     - 选择合适的存储引擎（如 OLTP 场景使用 InnoDB）

3. 语句执行流程检查

   - 使用 `EXPLAIN` 查看以下问题

   | 关注点       | 判断依据                              |
   | ------------ | ------------------------------------- |
   | 是否全表扫描 | `type = ALL` ❌                       |
   | 是否使用索引 | `key` 是否有值                        |
   | 是否回表     | `Extra` 是否包含 `Using index`        |
   | 是否临时表   | `Extra` 是否包含 `Using temporary` ❌ |
   | 是否排序     | `Extra` 是否包含 `Using filesort` ❌  |

4. 分库分表和缓存优化

   - 缓存热点数据 - Redis

   - 热门 SQL 缓存到 CDN、Redis

   - 分库分表解决单表过大或高并发瓶颈

我会首先通过慢查询日志、performance_schema 等工具定位慢 SQL，然后通过 `EXPLAIN` 分析执行计划，关注是否存在全表扫描、索引未命中、临时表或文件排序等问题。接着检查 SQL 是否合理、是否可以用覆盖索引、是否需要添加联合索引等。此外，对于高频读的热点数据，也会考虑使用 Redis 缓存，进一步提高性能。

### 索引失效的情况有哪些？

索引失效会导致**全表扫描（全索引扫描）**

索引失效的常见情况：

| 场景                         | 是否会失效 | 优化建议                       |
| ---------------------------- | ---------- | ------------------------------ |
| 函数、表达式处理索引字段     | 是         | 将函数移除，处理完再查询       |
| 隐式类型转换                 | 是         | 保持查询条件类型与字段一致     |
| LIKE 前缀 `%` 查询           | 是         | 使用后缀通配 `LIKE 'xxx%'`     |
| OR 条件混用索引和非索引字段  | 是         | 替换为 UNION，或加上索引       |
| 复合索引未使用最左前缀       | 是         | 遵循最左匹配原则               |
| !=、NOT IN、NOT EXISTS       | 是         | 尽量使用 IN、EXISTS 替代       |
| 查询返回数据量太大           | 是         | 优化 where 过滤条件            |
| 使用范围条件后再用其他索引列 | 部分失效   | 范围条件后续列可能不再使用索引 |

### 分别解释一下 RedoLog、UndoLog、BinLog？应用场景？

- **RedoLog**（重做日志）

  - 是 **InnoDB 引擎**特有的日志，用于保证事务的持久性

  - 记录了**对磁盘数据页的物理修改操作（逻辑变更后，页的二进制变化）**

  - 应用场景：崩溃恢复（系统宕机后，通过 Redo Log 重做未刷盘的数据页，**保证事务提交后的数据不会丢失**）

- **UndoLog**（回滚日志）

  - Undo Log 适用于 **事务回滚**，即数据恢复到修改前的状态

  - 记录了**数据被修改前的值**

  - 应用场景：事务回滚、MVCC 实现（多版本并发控制）、一致性读

- **BinLog**（归档日志）

  - Bin Log 是 **MySQL Server 层**的日志，所有引擎通用

  - 记录了**所有对数据库产生变更的 SQL 语句或其他事件格式**

  - 应用场景：主从复制（数据同步）、数据恢复

### 为什么使用 B+ 树作为索引的数据结构？为什么不用哈希表或二叉树？

数据库（特别是关系型数据库如 MySQL）**磁盘 I/O 访问的代价远高于内存计算**，因此选择索引的数据结构不仅要关注**时间复杂度**，还必须考虑**磁盘存储效率与访问效率**。

- **B+树**优点：

  - 减少磁盘 I/O：树的高度低

    - B+树是**多路平衡查找树**，每个非叶子节点可有 **上百上千个子节点**，因此 B+ 树高度非常低，减少了磁盘 I/O 次数。

  - B+树所有数据存在叶子节点，支持区间查询、范围查询

    - 所有数据只在 **叶子节点** 中；各叶子节点通过 **链表** 链接，天然支持 **范围查询**（`BETWEEN`，`ORDER BY`，`GROUP BY`），对于扫描一段数据，只需一次定位起点，接着顺序遍历即可。

  - 结构稳定、查询效率稳定

    - B+ 树的结构更平衡，所有 key 的查找路径长度一致，**查询效率稳定**

- 哈希表缺点：

| 缺点             | 说明                                                   |
| ---------------- | ------------------------------------------------------ |
| 无法进行范围查询 | 哈希表是无序的，不能处理 `WHERE age > 30` 类的区间查询 |
| 哈希冲突处理复杂 | 冲突越多，效率越低，不稳定                             |
| 空间利用率差     | 哈希表通常预留较大空间，浪费严重                       |
| 不支持排序       | 无法用于 `ORDER BY`、`GROUP BY`                        |

- 二叉树缺点：

| 缺点                   | 说明                                                       |
| ---------------------- | ---------------------------------------------------------- |
| 高度高                 | 即使是平衡树，百万数据也要十几层，导致磁盘 I/O 次数多      |
| 节点分布不适合磁盘存储 | 二叉树每个节点只存一个 key，不能充分利用磁盘页大小         |
| 不支持顺序遍历         | 虽然中序遍历有序，但没有链表指针，不如 B+ 树高效           |
| I/O 不友好             | 每访问一个节点就是一次磁盘读取，效率远低于 B+ 树页缓存策略 |

- B 树和 B+树 的区别：

| 特性                       | B 树             | B+ 树                                  |
| -------------------------- | ---------------- | -------------------------------------- |
| **数据存储位置**           | 数据存在所有节点 | **数据只存在叶子节点**，内节点只存索引 |
| **叶子节点之间是否有指针** | 无               | 有，双向/单向链表                      |
| **范围/区间查询**          | 支持，但效率低   | 非常高效（链表 + 顺序遍历）            |
| **内存命中效率**           | 一般（分布式）   | 更高（索引集中）                       |
| **访问路径是否固定**       | 取决于位置       | 所有数据查找路径等长                   |
| **磁盘读取效率**           | 较低（分散）     | 更高（节点大、扇出高）                 |
| **树的高度**               | 相对较高         | 更矮、更扁平                           |
| **数据库使用场景**         | 理论可用         | 实际数据库索引几乎都使用 B+ 树         |
